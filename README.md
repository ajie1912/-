# -程序还有些不太完善，但是日常用的话勉强够了，有时候会出现请求失败的，退出exe多试几次即可
运行会建立三个文件夹   image,image2,pdf如果有同名文件夹可能会引起错误 
如果程序运行过程中有问题欢迎联系   ajie1912@qq.com


以下为介绍：可以不用看

道客巴巴加载途径手机端和电脑端不一样（解析电脑端的时候刚好在抓手机的包，无意间发现手机端的方式比较好搞）
电脑端最后加载出一系列.ebt文件，貌似还需要特定的解析器 不太清楚
手机端的大致分为两种情况：
  
  # - @1：第一种 多用于加载pdf，也有部分ppt采用这种方式
    先由id构成一个url   https://m.doc88.com/doc.php?act=info&p_code=7582998794527&key=3854933de90d1dbb321d8ca29eac130a&v=1
    得到一大串加密字符串，经过类似base64方式的解密解析成一个字典，里面有一个gif_host还有一个gif_struct，分别存放了一些组成gif的url需要的字符串，
    还有一些别的信息，也可以提取出来，比如文档名，类型，多少页之类的
    最后一系列构成gif的url    var gif_url = gif_host+"/get-"+pageinfo.url+".gif"
    访问这些url就能得到最终构成文档需要的gif
    但是这种加载方式只能加载少于十页的，如果pdf超过十页，那就需要继续采用别的方式加载
      url1 = "https://mu3.doc88.com/p.do?id=" + str(id) + '-' + str(i) + '-' + "1024" + '-0-1-00-0-1-' + str(hour+"&callback=callback_" + str(now)    （now是13位时间戳）
        url2 = "https://mu3.doc88.com/p.do?id=" + str(id) + '-' + str(i) + '-' + "1024" + '-0-1-00-2-1-' + str(hour)（width一般取1024，hour是当前时间的整小时）
       先访问url1，应该会得到一串w=....h=....e=1  如果失败会得到e=0需要重新访问
     访问url1得到的session来回调访问url2才能得到一张gif
     用这个方式得到余下的gif  最后用Pypdf合并成一个pdf


   # - @2:大部分PPT文档
    第二种跟上面的加载余下部分内容有点类似
    把每页PPT切割成田字形状四块，分为00，01，10，11
    先访问url1 = "http://www.doc88.com/p-{}.html   拿到一个重要参数  imgHostKey
    url2 = "https://stat.doc88.com/mc.do?code={}&referer=https%253A%252F%252Fwww.doc88.com%252F&callback=callback&_{}=" 第一个校验链接，有时候也可以不用
	url3 = "https://{}.doc88.com/p.do?id={}-{}-600-0-4-11-0-1-{}&callback=callback&_{}="  # 第二个校验链接
    
       {}里面是几个参数，不逐一赘述了
     同样用包含e=1的session回调访问url4，url4 = "https://{}.doc88.com/p.do?id={}-{}-600-0-4-{}-2-1-{}"
     分别得到00，01，10，11四张，保存为1_00,1_01,1_10,1_11,2_00,2_01...........
    得到所有的块后合并成一个大的gif，最后再把所有的大gif合并pdf

   
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++（栅栏）


类型二常规方式比较慢，requests一个一个访问的话太慢太慢，370多页的ppt   1500来个请求大概得十来分钟，只好用asyncio异步非阻塞
效率确实高了很多 ，不到两分钟就能跑完
类型一理论上也可以用异步，个人觉得没什么必要也就没加，大致原理已经说明，感兴趣可以进一步优化，源码已经上传






